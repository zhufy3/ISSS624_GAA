---
title: "Take Home Exercise 1"
author: Fangyuan ZHU
execute: 
  warning: false
  message: false
format: html
editor: visual
---

# Geospatial Analysis for Water Points in Nigeria

## Background of the analysis

Water is the source of life on the Earth. Clean and accessible water is particularly critical for human life. Yet over 40% of the global population does not have access to sufficient clean water. Scarcity of water supply is a intractable problem to be solved in the world.

## Objectives

The main aim of this project is to use water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository. In order to address this complex problem, we focus on **Nigeria** as a study case and analyse the spatial distribution attributes of ***Not Functional Water Point*** in this project.

## 1. Data used

The data used in this project consists of two types:

-   aspatial data from [WPdx Global Data Repositories](https://www.waterpointdata.org/access-data/)

-   geospatial data of Nigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data.

## 2. Packages used

In this project, packages below are used to facilitate our analysis.

-   sf

-   tidyverse

-   tamp

-   spdep

-   funModeling

-   knitr

    ```{r}
    pacman::p_load(sf,tidyverse,tmap,spdep,funModeling,knitr)
    ```

## 3. Importing data into R environment

The data belonging to Nigeria should be extracted from the shapefiles *geo_export.* We use ***Projected*** ***Coordinate System*** whose identifier of EPSG is **26391**, so the *crs* = 26391. The function *st_read* of *sf* package is used to save the data in a simple feature data table. The data has been filtered when downloaded so no filter by *Nigeria* will be used here.

```{r eval=FALSE}
wp <- st_read(dsn = "geodata",
              layer = "geo_export",
              crs = 26391)
```

From the description above,

-   the data has 95008 features and 72 fields

-   Geometry type is POINT

-   Coordinate system is Projected System Minna/Nigeria west Belt

Then we upload the extracted tidy data table into the data file *geodata.*

```{r eval=FALSE}
write_rds(wp,"geodata/wp_nga.rds")
```

Now we import Nigeria LGA boundary data into R environment using the same function, and also extract Projected Coordinate System to match the water point data.

```{r eval=FALSE}
nga <- st_read(dsn = "geodata",
               layer = "geoBoundaries-NGA-ADM2",
               crs = 26391)
```

From the description above,

-   Geometry type of the data is MULTIPOLYGON

-   Coordinate system is Projected System Minna/Nigeria west Belt

## 4. Data Wrangling

### 4.1 Data Issues

#### 4,1,1 Missing Value Check

First let us check if there are missing values in the extracted data tables.

```{r eval=FALSE}
summary(nga[rowSums(is.na(nga))!=0,])
```

As we can see the summary information above, there is no missing value in LGA boundary data.

```{r eval=FALSE}
summary(wp[rowSums(is.na(wp))!=0,])
```

As we can see from information above, there are so many missing values in the water point data. For example, there are 94994 missing values in *clean_adm4,* 46891 missing values in *install_ye*, and so on.

#### 4.1.2 Recoding Missing Values into Strings

Next, we recode these missing values of *status_cle*, which we will use in the subsequent analysis into *"Unknown"* to proceed our analysis.

```{r eval=FALSE}
wp_nga <- read_rds("geodata/wp_nga.rds") %>%
  mutate(status_cle = replace_na(status_cle, "Unknown"))
```

### 4.2 Data Processing

#### 4.2.1 Glimpse The Data Tables

We take a check at our data tables with *glimpse()* of *dplyr* package.

```{r eval=FALSE}
glimpse(nga)
```

We can see that the table has 774 rows and 6 columns, which are in *character* and *multipolygon* classes.

-   *shapename*

-   *Level*

-   *shapeID*

-   *shapeGroup*

-   *shapeType*

-   *geometry.*

    ```{r eval=FALSE}
    glimpse(wp_nga)
    ```

We can see that the table has 95008 rows and 73 columns.

Then let us have a quick look at the geometry of the geospatioal data by using *plot()* and *st_geometry()* of *sf* package.

```{r eval=FALSE}
plot(st_geometry(nga))
```

![](images/000005.png)

#### 4.2.2 Distribution of The Data in *status_cle* Field

Then we can display the distribution of the data in *status_cle* field using *freq().*

```{r eval=FALSE}
freq(data=wp_nga, 
     input = 'status_cle')
```

![](images/000011.png)

From the hist graph, it is shown that ***Functional Water Point*** takes the most portion of **48.29 %** within the *status_cle* field. Next is ***Non-Functional Water Point**,* our objective analysed in this project, which takes **30.93%** in the field.

#### 4.2.3 Points in Polygons

We first extract *Functional* water point, on which we focus to analyse, from the whole *status_cle* field, and write the simple feature data table into *rds* files.

```{r eval=FALSE}
wpt_functional <- wp_nga %>%
  filter(status_cle %in%
           c("Functional", 
             "Functional but needs repair",
             "Functional but not in use"))
```

We can check the proportion of each attribute in *Functional Water Point* as shown below.

```{r eval=FALSE}
freq(data=wpt_functional, 
     input = 'status_cle')
```

![](images/000010.png)

We then extract *Non-Functional* water point from the whole *status_cle* field, and write the simple feature data table into *rds* files.

```{r eval=FALSE}
wpt_nonfunctional <- wp_nga %>%
  filter(status_cle %in%
           c("Abandoned/Decommissioned", 
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
```

We can check the proportion of each attribute in *Non-Functional Water Point* as shown below.

```{r eval=FALSE}
freq(data=wpt_nonfunctional, 
     input = 'status_cle')
```

![](images/000010-01.png)

Now we count the number of *Total,* *Functional* and *Non-Functional* water points at LGA level using *st_intersects()*.

```{r eval=FALSE}
FC<- lengths(st_intersects(nga, wpt_nonfunctional))
NFC<- lengths(st_intersects(nga, wpt_functional))
TL<-lengths(st_intersects(nga, wp_nga))
```

We merge the count of *Total Water Point, Functional Water Point* and *Non-Functional Water Point* in polygons with LGA data table *nga* as *nga_wp.*

```{r eval=FALSE}
nga_wp <- nga %>% 
  mutate(`total wpt` = TL) %>%
  mutate(`wpt functional` = FC) %>%
  mutate(`wpt non-functional` = NFC)
```

Then we calculate the portion of numbers of functional and non-functional water points in each polygon, and merge it with *nga* data table.

```{r eval=FALSE}
nga_wp <- nga_wp %>%
  mutate(pct_functional = `wpt functional`/`total wpt`) %>%
  mutate(`pct_non-functional` = `wpt non-functional`/`total wpt`)
```

Now we save the data table into *rds* format with the chunk below. And delete other raw data.

```{r eval=FALSE}
write_rds(nga_wp, "geodata/nga_wp.rds")
```

### 5. Geospatial Analysis

#### 5.1 Visualizing Water Point Indicator

Now we can visualize the distributions of proportions of *Functional* and *Non-Functional water point* using *ggplot2* package.

```{r}
nga_wp <- read_rds("geodata/nga_wp.rds")
ggplot(data=nga_wp, 
       aes(x= as.numeric(`pct_non-functional`)))+
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light blue") +
  labs(title = "Are non-functional water points even distributed in Nigeria?",
      x = "Non-Functional Water Points Proportion",
      y = "Frequency")
```

We can see that the distribution of percentage of non-functional water point is similar to normal distribution, with little skewness.

Now, we are going to prepare a basemap and a choropleth map showing the distribution of *Non-Functional* water point by using *qtm()* of **tmap** package.

```{r}

equal <- tm_shape(nga_wp) +
  tm_fill("wpt non-functional",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification",
            legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)

quantile <- tm_shape(nga_wp) +
  tm_fill("wpt non-functional",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification",
            legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

### 6 Global Spatial Autocorrelation

Before we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The polygon contiguity method is effective when polygons are similar in size and distribution, and when spatial relationships are a function of polygon proximity.

The **fixed distance method** works well for point data. It is often a good option for polygon data when there is a **large variation** in polygon size. Because we have had a quick look at the geometry, the variation in polygon size is quite large, and the distribution of the indicator **is not largely skewed**, so we choose fixed distance matrix.

#### 6.1 Computing Contiguity Based on Fixed Distance

##### 6.1.1 Determine the cut-off distance

To get our longitude values we map the st_centroid function over the
geometry column of us.bound and access the longitude value through
double bracket notation \[\[\]\] and 1. This allows us to get only the
longitude, which is the first value in each centroid.

```{r}
longitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[1]])
latitude <- map_dbl(nga_wp$geometry, ~st_centroid(.x)[[2]])
coords <- cbind(longitude, latitude)
head(coords)
```

Then, we need to determine the upper limit for distance band by using the steps below:

-   Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using [*knearneigh()*](https://r-spatial.github.io/spdep/reference/knearneigh.html) of **spdep**.

-   Convert the knn object returned by *knearneigh()* into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using [*knn2nb()*](https://r-spatial.github.io/spdep/reference/knn2nb.html).

-   Return the length of neighbour relationship edges by using [*nbdists()*](https://r-spatial.github.io/spdep/reference/nbdists.html) of **spdep**. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.

Remove the list structure of the returned object by using [**unlist()**](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/unlist).

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest nearest neighbour distance is **71.661 km**, and the least nearest neighbour distance is **2.662 km,** so using this as the upper threshold gives certainty that all units will have at least one neighbour.

##### 6.1.2 Computing fixed distance weight matrix

Now, we will compute the distance weight matrix by using *dnearneigh()* as shown in the code chunk below.

```{r}
wm_d72 <- dnearneigh(coords, 0, 72, longlat = TRUE)
wm_d72
```

We can display the content of the matrix by using *str()*.

```{r}
str(wm_d72)
```

##### 6.1.3 Plotting distance based neighbours

Let us now plot the weight matrix using the code chunk below.

```{r}
plot(nga_wp$geometry, border="lightgrey")
plot(wm_d72,add=TRUE, coords)
plot(k1, coords, add=TRUE, col="red", length=0.08)
```

The red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 72km.

Next, we need to assign weights to each neighboring polygon based both on *Fixed Distance*. In our case, each neighboring polygon will be assigned equal weight (style="W").

```{r}
rswm_f <- nb2listw(wm_d72, 
                   style="W", 
                   zero.policy = TRUE)
print(rswm_f,  zero.policy = TRUE)
```

#### 6.2 Global Spatial Autocorrelation Test

The Null Hypothesis for Spatial Randomness:

-   Observed spatial pattern of values is equally likely as any other spatial pattern.

-   Values at one location do not depend on values at other (neighbouring) locations.

-   Under spatial randomness, the location of values may be altered without affecting the information content of the data.

    We mainly have two methods to test the teospatial global autocorrelation.

-   Moran's I Test

-   Geary's C Test

##### 6.2.1 Moran's I Test

As the snippet shows, there are some percentage becomes *NaN* because the *total wpt* is 0. We should recode these NA as 0.

![](images/tempsnip.png)

```{r}
nga_wp <- nga_wp %>%
  mutate(pct_functional = replace_na(pct_functional,0))%>%
  mutate(`pct_non-functional`=replace_na(`pct_non-functional`,0))

write_rds(nga_wp,"geodata/nga_wp.rds")
```

The code chunk below performs Moran's I statistical testing using *moran.test()* of **spdep**.

```{r}
moran.test(nga_wp$`pct_non-functional`, 
           listw=rswm_f, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

From the summary of the test result, we can see that the **p-value** is less than **0.05**, which means we have evident reasons to reject the Null Hypothesis that the percentage of Non-Functional water point is randomly distributed across the country.

##### 6.2.2 Computing Monte Carlo Moran's I

We already get the result of the Moran's I Test, but we can confirm the test by simulating Monte Carlo.

```{r}
set.seed(1234)
bperm= moran.mc(nga_wp$`pct_non-functional`, 
                listw=rswm_f, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```

From the summary of the test result, we can see that the **p-value** is **0.001,** still less than **0.05**, which means we have evident reasons to reject the Null Hypothesis that the percentage of Non-Functional water point is randomly distributed across the country. And the **statistic = 0.48857 \>0.** For the **I statistic,** if it is positive (I\>0): Clustered, observations tend to be similar.

##### 6.2.3 Geary's C Test

The code chunk below performs Geary's C test for spatial autocorrelation by using [*geary.test()*](https://r-spatial.github.io/spdep/reference/geary.test.html) of **spdep**.

Now we can do the Geary's C test:

```{r}
geary.test(nga_wp$`pct_non-functional`, listw=rswm_f, zero.policy = TRUE)
```

From the summary of the test result, we can see that the **p-value** is less than **0.05**, which means we have evident reasons to reject the Null Hypothesis that the percentage of Non-Functional water point is randomly distributed across the country. The **Geary C statistic = 0.5091973810 \< 1.**

##### 6.2.4 Computing Monte Carlo Geary's C

The code chunk below performs permutation test for Geary's C statistic by using [*geary.mc()*](https://r-spatial.github.io/spdep/reference/geary.mc.html) of **spdep**.

```{r}
set.seed(1234)
bperm=geary.mc(nga_wp$`pct_non-functional`, 
               listw=rswm_f, zero.policy = TRUE,
               nsim=999)
bperm
```

From the summary of the test result, we can see that the **p-value** is **0.001,** still less than **0.05**, which means we have evident reasons to reject the Null Hypothesis that the percentage of Non-Functional water point is randomly distributed across the country. And the **statistic = 0.5092 \< 1.** For the **c statistic,** if it is Small c value (\<1) : Clustered, observations tend to be similar.

#### 6.3 Clusters and Outliers Analysis

##### 6.3.1 Computing local Moran's I

The code chunks below are used to compute local Moran's I of *pct_non-functional* at the ADM2 level.

```{r}
fips <- order(nga_wp$shapeName)
localMI <- localmoran(nga_wp$`pct_non-functional`, rswm_f,zero.policy = TRUE)
head(localMI)
```

*localmoran()* function returns a matrix of values whose columns are:

-   Ii: the local Moran's I statistics

-   E.Ii: the expectation of local moran statistic under the randomisation hypothesis

-   Var.Ii: the variance of local moran statistic under the randomisation hypothesis

-   Z.Ii:the standard deviate of local moran statistic

-   Pr(): the p-value of local moran statistic

##### 6.3.2 Mapping the local Moran's I

Before mapping the local Moran's I map, it is wise to append the local Moran's I dataframe (i.e. localMI) onto nga_wp SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called *nga_wp.localMI*.

```{r}
nga.localMI <- cbind(nga_wp,localMI)%>%
  rename(Pr.Ii = Pr.z....E.Ii..)
```

```{r}
tm_shape(nga.localMI) +
  tm_fill(col = "Ii", 
          style = "pretty",
          palette = "RdBu",
          title = "local moran statistics") +
  tm_borders(alpha = 0.5) +
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)
```

The plot above shows that the regions of the top right of the country in blue has the most positive clusters, meaning percentage of non-functional water points in these regions are quite similar. Regions in pink have negative correlations, meaning percentage of non-functional water points in these regions are quite discrete.

##### 6.3.3 Mapping the local Moran's p-values

The choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.

```{r}
tm_shape(nga.localMI) +
  tm_fill(col = "Pr.Ii", 
          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),
          palette="-Blues", 
          title = "local Moran's I p-values") +
  tm_borders(alpha = 0.5) +
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)
```

The figure above shows clearly regions having distinct cluster or outlier patterns, instead of randomly distributed one. Regions in more deep color, the cluster or outlier pattern is more significant.

##### 6.3.4 Creating a LISA Cluster Map

The LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.

###### 6.3.4.1 Plotting Moran scatterplot

```{r}
nci<- moran.plot(nga_wp$`pct_non-functional`, rswm_f,
                  labels=as.character(nga_wp$shapeName),
                  zero.policy = TRUE,
                  xlab="Pct non-functional", 
                  ylab="Sptially Lag Pct non-functional")
```

Notice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high percentage of non-functional water point and are surrounded by other areas that have the average level of pct_non-functional, i.e. the high-high locations.

###### 6.3.4.2 Plotting Moran scatterplot with standardised variable

First we will use [*scale()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/scale) to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.

```{r}
nga_wp$z.pctnon <- scale(nga_wp$`pct_non-functional`) %>% 
  as.vector 
```

Now, we are ready to plot the Moran scatterplot again by using the code chunk below.

```{r}
nci2 <- moran.plot(nga_wp$z.pctnon, rswm_f,
                  labels=as.character(nga_wp$shapeName),
                  zero.policy = TRUE,
                  xlab="Pct non-functional", 
                  ylab="Sptially Lag Pct non-functional")
```

###### 

6.3.4.3 Preparing LISA map classes

The code chunks below show the steps to prepare a LISA cluster map.

```{r}
quadrant <- vector(mode="numeric",length=nrow(localMI))
```

Next, derives the spatially lagged variable (pct_non-functional) and centers the spatially lagged variable around its mean.

```{r}
nga_wp$lag_pctnon <- lag.listw(rswm_f, nga_wp$`pct_non-functional`,zero.policy = TRUE)
DV <- nga_wp$lag_pctnon - mean(nga_wp$lag_pctnon)     
```

This is follow by centering the local Moran's around the mean.

```{r}
LM_I <- localMI[,1] - mean(localMI[,1])    
```

We will set a statistical significance level as 95% for the local Moran.

```{r}
signif <- 0.05       
```

These four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.

```{r}
quadrant[DV <0 & LM_I>0] <- 1
quadrant[DV >0 & LM_I<0] <- 2
quadrant[DV <0 & LM_I<0] <- 3  
quadrant[DV >0 & LM_I>0] <- 4      
```

Lastly, places non-significant Moran in the category 0.

```{r}
quadrant[localMI[,5]>signif] <- 0
```

##### 6.3.5 Plotting LISA map

Now, we can build the LISA map by using the code chunks below.

```{r}
nga.localMI$quadrant <- quadrant
colors <- c("#ffffff", "#2c7bb6", "#abd9e9", "#fdae61", "#d7191c")
clusters <- c("insignificant", "low-low", "low-high", "high-low", "high-high")

tm_shape(nga.localMI) +
  tm_fill(col = "quadrant", 
          style = "cat", 
          palette = colors[c(sort(unique(quadrant)))+1], 
          labels = clusters[c(sort(unique(quadrant)))+1],
          popup.vars = c("")) +
  tm_view(set.zoom.limits = c(11,17)) +
  tm_borders(alpha=0.5)
```

The map above shows that percentages of non-functional water points in areas in red are high and clustered; percentages in deep blue are low and sparsed; percentages in light blue are low outliers among high neighbours; percentages in orange are high outliers among low neighbours.

### 7. Hot Spot and Cold Spot Area Analysis

Beside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas. Spatial statistics to detect spatial anomalies is the Getis and Ord's G-statistics

The analysis consists of three steps:

-   Deriving spatial weight matrix

-   Computing Gi statistics

-   Mapping Gi statistics

#### 7.1 Gi statistics using fixed distance

First, *nb2listw()* is used to convert the nb object into spatial weights object. Because we produce *wm_d72* with *style-"W",* we still use W to convert the object.

```{r}
wm72_lw <- nb2listw(wm_d72, style = 'W')
summary(wm72_lw)
```

From the summary above, we can see 5 regions have least neighbour of 1, and 1 region has most neighbours of 70. Then we compute the Gi statistics with below code chunk.

```{r}
fips <- order(nga_wp$shapeName)
gi.fixed <- localG(nga_wp$`pct_non-functional`, wm72_lw)
gi.fixed
```

Next, we join the Gi values to their corresponding sf data frame by using the code chunk below.

```{r}
nga.gi <- cbind(nga_wp, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

#### 7.2 Mapping Gi values with fixed distance weight

The code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.

```{r}
rmp <- qtm(nga_wp,"pct_non-functional")

Gimap <-tm_shape(nga.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)

tmap_arrange(rmp, Gimap, asp=1, ncol=2)
```

From figures above, it is shown that areas in the north of the country, more specifically areas in red, is a cluster of high values of percentage of non-functional water point; while areas in the south and north east of the country, more specifically areas in deep blue, are the opposite of clusters with low values of percentage of non-functional water point.
