---
title: "Take-home Exercise 2"
author: "ZHU Fangyuan"
execute: 
  warning: false
  message: false
format: html
editor: visual
---

# Take-home Exercise 2: Regionalisation of Multivariate Water Point Attributes with Non-spatially Constrained and Spatially Constrained Clustering Methods

## Objectives

In this take-home exercise we will regionalise Nigeria by using the following measures:

-   Total number of functional water points

-   Total number of nonfunctional water points

-   Percentage of functional water points

-   Percentage of non-functional water points

-   Percentage of main water point technology (i.e. Hand Pump)

-   Percentage of usage capacity (i.e. \< 1000, \>=1000)

-   Percentage of rural water points

-   Percentage of water points with different density of nearby population

-   Percentage of water points with different density of local (\<1km) population

## Overview

In this in-class exercise, we will learn several useful ways to deal with geospatial and aspatial data of **Nigeria** case! Let us get started now!

## 1 Packages Used

Packages below will be used in this in-class exercise:

-   ***sf*** : importing and processing geospatial data

-   ***tidyverse:*** importing and processing non-spatial data. In this exercise, readr package will be used for importing wkt data and dplyr package will be used to wrangling the data

-   **rgdal, spdep** for spatial data handling

-   **readr, ggplot2, dplyr** for attribute data handling

-   **tmap** for choropleth mapping

-   **corrplot, ggpubr, TSP, heatmaply** for multivariate data visualisation

-   **cluster, ClustGeo** for cluster analysis

```{r}
pacman::p_load(rgdal, spdep, tmap, sf, readr, ggplot2, dplyr,
               ggpubr, cluster, factoextra, NbClust,
               TSP, heatmaply, corrplot, psych, tidyverse,ClustGeo, funModeling, knitr)
```

## 2 Data Used

In this exercise, two data sets will be used:

-   **Aspatial data:** from WPdx Global Data Repositories. We will use the WPdx+ data set.
-   **Geospatial data:** Nigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data from the Humanitarian Data Exchange portal or geoBoundaries.

## 3 Data Preparation

### 3.1 Importing water point data

First, let us import the data used into the R environment using code below.

And the function `filter()` of ***dplyr*** will be used to filter data only belonging to Nigeria.

```{r eval=FALSE}
wp_nga <- read_csv("aspatial/WPdx.csv")%>%
  filter(`#clean_country_name`=="Nigeria")
```

Noted that the data frame contains 95008 observations and 70 variables.

### 3.2 Convert Well Known Text (wkt) data

Notice that the newly imported tibble data frame (i.e. wp_nga) contains a field called *New Georeferenced Column* which represent spatial data in a textual format. In fact, this kind of text file is popularly known as ***Well Known Text*** in short ***wkt***. So we need to convert the *wkt* data into **sf** data.frame for subsequent analysis.

First, `st_as_sfc()` of ***sf*** package is used to derive a new field called *Geometry* as shown in the code chunk below.

```{r eval=FALSE}
wp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)
```

Next, `st_sf()` will be used to convert the *tibble* data frame into *sf* data frame. In addition, we use ***Projected Coordinate System*** for convenience in our analysis, so we set the *EPSG* code as ***26391.***

```{r eval=FALSE}
wp_sf <- st_sf(wp_nga) %>%
  st_transform(crs=26391)
wp_sf
```

The output reveals that we have:

-   Simple feature collection withe 95008 features and 70 fields;

-   Geometry type: POINT;

-   Projected CRS: Minna / Nigeria west belt.

### 3.3 Importing Nigeria LGA boundary data

Now we import the geospatial data with the same ***Projected Coordinate System (EPSG code:26391)*** into the R environment, and we only use *shapeName* column because this boundary data only provides a basic map of the country.

```{r eval=FALSE}
nga<-st_read(dsn = "geospatial",
             layer = "geoBoundaries-NGA-ADM2")%>%
  select(shapeName)%>%
  st_transform(crs=26391)
```

The output reveals that we have:

-   Simple feature collection withe 774 features and 5 fields;

-   Geometry type: MULTIPOLYGON;

-   Projected CRS: Minna / Nigeria west belt.

Now we can write the tidy *sf* data frame ***nga*** as a *rds* files with code chunk below.

```{r eval=FALSE}
write_rds(nga,"geodata/nga.rds")
```

## 4 Data Wrangling

### 4.1 Data issues

Before we go ahead, we are supposed to deal with data issues first.

#### 4.1.1 Duplicate fields and features

We now come to check if there are duplicate columns in the *wp_sf* data frame using code chunk below.

```{r eval=FALSE}
dup_col <- duplicated(t(wp_sf))
colnames(wp_sf[dup_col])
```

Noticed that there are 7 duplicated columns *#clean_adm4, #rehabilitator, #fecal_coliform_presence, #scheme_id, lon_deg_original, updated_timestamp* and *Geometry*. However, taking a glimpse on the data table, former 6 columns have duplicated columns because their values are all missed. And as shown in sippet below, we do see column *#water_tech_clean* and *#water_tech_category* are actually the same with some supplementary notes in column *#water_tech_clean*.

![](images/tempsnip-01.png)

Therefore, we only use *#water_tech_clean* as our object of analysis because it describe observations more simply.

We now check if there are duplicate rows in the *wp_sf* data frame using code chunk below.

```{r eval=FALSE}
dup=which(duplicated(wp_sf))
dup
```

As the output reveals, there are no observations duplicated in *wp_sf* data frame. Then we use the same codes to check if there are duplicated columns and rows in the *nga* data frame.

```{r eval=FALSE}
nga<-read_rds("geodata/nga_wp.rds")
dup_coln<-which(duplicated(t(nga)))
dup_n<-which(duplicated(nga))
print(dup_n)
print(dup_coln)
```

As the output reveals, there are no duplicated columns or rows in the *nga* data frame.

#### 4.1.2 Missing values

For convenience case, we first rename the columns we pay attention to in this project, which are:

-   *#status_clean*

-   *#water_tech_clean* or *#water_tech_category* (these two columns are identical)

-   *is_urban*

-   *usage_capacity*

We first rename columns *#status_clean,* *#water_tech_category* and *usage_capacity* which are redundant.

```{r eval=FALSE}
wp_sf<-wp_sf%>%
  rename(`status_cle`=`#status_clean`)%>%
  rename(water_tech=`#water_tech_category`)%>%
  rename(usage_cap=usage_capacity)%>%
  rename(wptpp=water_point_population)%>%
  rename(locpp=local_population_1km)
```

Now columns *#status_clean* and *#water_tech_category* are changed as *status_cle,* *water_tech* and *usage_cap.*

Then let us select the columns which will be used in the analysis, to make the data frame tidier by using codes below.

```{r eval=FALSE}
wp_sf<-wp_sf%>%
  select(c(1,10,22,42,43,46,47))
write_rds(wp_sf,"geodata/wp_sf.rds")
```

Let us see some statistics summary of the data frame with codes below and check missing values in the *wp_sf* data frame.

```{r eval=FALSE}
summary(wp_sf[rowSums(is.na(wp_sf))!=0,])
```

Noted from the output above that the variable *water_tech* has 11225 *NAs,* so does variable *status_cle. wptpp* and *locpp* both have 529 NAs. And no missing values in other variables which are *row_id,* *usage_cap* and *is_urban.*

Let us see statistics summary of the missing values in LGA boundary data *nga* data frame with the same codes shown below.

```{r eval=FALSE}
summary(nga[rowSums(is.na(nga))!=0,])
```

As we can see the summary information above, there is no missing value in LGA boundary data.

#### 4.1.3 Recoding missing values

In order to smoothly proceed our analysis without errors and warnings, it will make sense to recode the *NAs* in columns, however, we may consider replace the *NAs with different methods in different contexts.* Therefore, for ***water_tech*** with **mode** of the column's values.

First we write a function ***getmode*** to get the mode of a list of values using codes below.

```{r}
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

```

Then we replace the missing values with **Mode of the column's values.**

```{r eval=FALSE}
wp_sf<-wp_sf%>%
  mutate(water_tech=replace_na(water_tech,getmode(water_tech)))
```

However, for *status_cle,* it is irrational to use **mode** to replace the missing values.

```{r eval=FALSE}
getmode(wp_sf$status_cle)
```

Because as the output shown above, the mode for *status_cle* is *Functional,* but **from my perspective,** it is mostly impossible that functional water points were missed to be recorded. Therefore, those missing values are probably nonfunctional water points. We replace missing values in *status_cle* with *Non-Functional.*

```{r eval=FALSE}
wp_sf<-wp_sf%>%
  mutate(status_cle = replace_na(status_cle, "Non-Functional"))
```

In addition, we should check the status of water points where there are missing values in *water point population* and *local population \<1km* using code chunk below.

```{r eval=FALSE}
wp_sf[is.na(wp_sf$wptpp)==1,]%>%
  group_by(status_cle)%>%
  summarise(n=n())

wp_sf[is.na(wp_sf$locpp)==1,]%>%
  group_by(status_cle)%>%
  summarise(n=n())
```

![](images/paste-6CFB6EF5.png)

Noticed that water points where there are missing values for populations are either *Abandoned/Decommissioned* or *Non-Functional water points.* Therefore, we assume there are no people living where there is a missing value and recode NAs with 0 as shown below.

```{r eval=FALSE}
wp_sf<-wp_sf%>%
  mutate(wptpp = replace_na(wptpp,0))

wp_sf<-wp_sf%>%
  mutate(locpp = replace_na(locpp,0))
```

Before we start our journey on creating new variables, let us take a look on statistics summary of the *wp_sf* data frame with codes below.

```{r eval=FALSE}
wp_sf%>%
  group_by(water_tech)%>%
  summarise(n=n())
```

![](images/paste-02796709.png)

```{r eval=FALSE}
wp_sf%>%
  group_by(status_cle)%>%
  summarise(n=n())
```

```{r eval=FALSE}
wp_sf%>%
  group_by(usage_cap)%>%
  summarise(n=n())

wp_sf%>%
  group_by(is_urban)%>%
  summarise(n=n())
```

![](images/paste-C3A8DF7B.png){width="200"}

## ![](images/paste-E7E8C147.png){width="200"}

## 5 Data Wrangling

### 5.1 Derive new variables

Then we are supposed to extract variables we will pay attention to in this exercise, and store them in specific data frame. These variables are:

-   Total number of **functional** water points

-   Total number of **non-functional** water points

-   Total number of main water point technology (i.e. ***Handpump***)

-   Total number of **usage** **capacity**

-   Total number of **rural** water points

-   Total number of water points at different **nearby population densities**

-   Total number of water points at different **local (\<1 km) population densities**

We first create a data frame for *Non-Functional water points.* For rational reasons, *Abandoned/Decommissioned* and *Abandoned* should also be considered as *Non-Functional water points,* so we put water points belong to there two definitions into Non-Functional data frame using codes below.

```{r eval=FALSE}
wpt_nonfunctional <- wp_sf %>%
  filter(status_cle %in%
           c("Abandoned/Decommissioned", 
             "Abandoned",
             "Non-Functional",
             "Non functional due to dry season",
             "Non-Functional due to dry season"))
```

We now create data frames for *Functional water points, Hand-pump water points, usage capacity \>=1000 water points, usage capacity\<1000 water points,* *rural water points,* *water points* *with dense nearby population* and *water points with dense local (\<1 km) population* using the same methods.

```{r eval=FALSE}
wpt_functional <- wp_sf %>%
  filter(status_cle %in%
           c("Functional",
             "Functional but needs repair",
             "Functional but not in use"))

wpt_hand <- wp_sf %>%
  filter(water_tech %in%
           "Hand Pump")

wpt_cap_over <- wp_sf %>%
  filter(usage_cap>=1000)

wpt_cap_less<-wp_sf%>%
  filter(usage_cap<1000)

wpt_rural<-wp_sf%>%
  filter(is_urban==FALSE)

wpt_wptpp<-wp_sf%>%
  filter(wptpp>mean(wptpp))

wpt_locpp<-wp_sf%>%
  filter(locpp>mean(locpp))

```

Now we count the number of *Total,* *Functional water points, Non-Functional water points, Hand-pump water points, usage capacity \>=1000, usage capacity\<1000, rural water points,* *water points* *with dense nearby population* and *water points with dense local (\<1 km) population* at LGA level using *st_intersects()*.

```{r eval=FALSE}
FC<- lengths(st_intersects(nga, wpt_nonfunctional))
NFC<- lengths(st_intersects(nga, wpt_functional))
TT<-lengths(st_intersects(nga, wp_sf))
HP<-lengths(st_intersects(nga,wpt_hand))
UO<-lengths(st_intersects(nga,wpt_cap_over))
UL<-lengths(st_intersects(nga,wpt_cap_less))
RR<-lengths(st_intersects(nga,wpt_rural))
WP<-lengths(st_intersects(nga,wpt_wptpp))
LP<-lengths(st_intersects(nga,wpt_locpp))
```

We merge the count of *Total,* *Functional water points, Non-Functional water points, Hand-pump water points, usage capacity \>=1000, usage capacity\<1000,* *rural water points, water points* *with dense nearby population* and *water points with dense local (\<1 km) population* in polygons with LGA data table *nga* as *nga_wp* using codes below.

```{r eval=FALSE}
nga_wp <- nga %>% 
  mutate(`total wpt` = TT) %>%
  mutate(`functional wpt` = FC) %>%
  mutate(`non-functional wpt` = NFC)%>%
  mutate(`hand-pump wpt`=HP)%>%
  mutate(`usage cap>=1000`=UO)%>%
  mutate(`usage cap<1000`=UL)%>%
  mutate(`rural wpt`=RR)%>%
  mutate(`wpt pop`=WP)%>%
  mutate(`local pop`=LP)
```

Then we calculate the percentages of numbers of *Functional water points, Non-Functional water points, Hand-pump water points, usage capacity \>=1000, usage capacity\<1000,* *rural water points, water points* *with dense nearby population* and *water points with dense local (\<1 km) population* in each polygon, and merge it with *nga_wp* data table.

```{r eval=FALSE}
nga_wp <- nga_wp %>%
  mutate(pct_functional = `functional wpt`/`total wpt`) %>%
  mutate(`pct_non-functional` = `non-functional wpt`/`total wpt`) %>%
  mutate(`pct_hand-pump`=`hand-pump wpt`/`total wpt`)%>%
  mutate(`pct_cap>=1000`=`usage cap>=1000`/`total wpt`)%>%
  mutate(`pct_cap<1000`=`usage cap<1000`/`total wpt`)%>%
  mutate(`pct_rural`=`rural wpt`/`total wpt`)%>%
  mutate(`pct_pop`=`wpt pop`/`total wpt`)%>%
  mutate(`pct_localpop`=`local pop`/`total wpt`)

```

We can quickly look at the data frame by using codes below.

```{r eval=FALSE}
head(nga_wp,10)
```

As shown, there are some percentage becomes *NaN* because the *total wpt* is 0. We should recode these NA as 0.

```{r eval=FALSE}
nga_wp <- nga_wp %>%
  mutate(pct_functional = replace_na(pct_functional,0))%>%
  mutate(`pct_non-functional`=replace_na(`pct_non-functional`,0))%>%
  mutate(`pct_hand-pump`=replace_na(`pct_hand-pump`,0))%>%
  mutate(`pct_cap>=1000`=replace_na(`pct_cap>=1000`,0))%>%
  mutate(`pct_cap<1000`=replace_na(`pct_cap<1000`,0))%>%
  mutate(`pct_rural`=replace_na(`pct_rural`,0))%>%
  mutate(`pct_pop`=replace_na(`pct_pop`,0))%>%
  mutate(`pct_localpop`=replace_na(`pct_localpop`,0))

```

We can quickly look at the data frame after modified by using codes below.

```{r eval=FALSE}
head(nga_wp,10)
```

Now we store the file *nga_wp* as a rds file.

```{r eval=FALSE}
write_rds(nga_wp,"geodata/nga_wp.rds")
```

### 5.2 Exploratory Data Analysis (EDA)

Counts of variables only have little meaning for our analysis. We focus on the percentage of number for each variable in a specific polygon. We now plot the histgram of frequency of ratio of all percentages to analyse their distributions.

```{r}
nga_wp<-read_rds("geodata/nga_wp.rds")
pct_func <- ggplot(data=nga_wp, 
             aes(x= `pct_functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light grey")

pct_nonfunc <- ggplot(data=nga_wp, 
             aes(x= `pct_non-functional`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light grey")

pct_hand <- ggplot(data=nga_wp, 
             aes(x= `pct_hand-pump`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light grey")

pct_capov <- ggplot(data=nga_wp, 
             aes(x= `pct_cap>=1000`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light grey")

pct_capls <- ggplot(data=nga_wp, 
             aes(x= `pct_cap<1000`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light grey")

pct_rural <- ggplot(data=nga_wp, 
             aes(x= `pct_rural`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light grey")

pct_pop <- ggplot(data=nga_wp, 
             aes(x= `pct_pop`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light grey")

pct_localpop <- ggplot(data=nga_wp, 
             aes(x= `pct_localpop`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light grey")

ggarrange(pct_func, pct_nonfunc, pct_hand, pct_capov, pct_capls, pct_rural, pct_pop, pct_localpop,
          ncol = 2, 
          nrow = 4)
```

Noted that the percentage of *Hand pump water points, water points with usage capacity \>=1000, water points with usage capacity \<1000 and rural water points* are highly skewed. More specific, in ADMIN2 districts, most of them have half functional water points and non-functional water points and most of them have water points with usage capacity less than 1000. In addition, most of the water points are located in rural areas, supported by hand pumps and with relatively dispersed population.

Now we can also check outliers of them using boxplots.

```{r}
pct_func <- ggplot(data=nga_wp, 
             aes(x= `pct_functional`)) +
  geom_boxplot(color="black", 
                 fill="light grey")

pct_nonfunc <- ggplot(data=nga_wp, 
             aes(x= `pct_non-functional`)) +
  geom_boxplot(color="black", 
                 fill="light grey")

pct_hand <- ggplot(data=nga_wp, 
             aes(x= `pct_hand-pump`)) +
  geom_boxplot(color="black", 
                 fill="light grey")

pct_capov <- ggplot(data=nga_wp, 
             aes(x= `pct_cap>=1000`)) +
  geom_boxplot(color="black", 
                 fill="light grey")

pct_caple <- ggplot(data=nga_wp, 
             aes(x= `pct_cap<1000`)) +
  geom_boxplot(color="black", 
                 fill="light grey")

pct_rural <- ggplot(data=nga_wp, 
             aes(x= `pct_rural`)) +
  geom_boxplot(color="black", 
                 fill="light grey")

pct_pop <- ggplot(data=nga_wp, 
             aes(x= `pct_pop`)) +
  geom_boxplot(color="black", 
                 fill="light grey")

pct_localpop <- ggplot(data=nga_wp, 
             aes(x= `pct_localpop`)) +
  geom_boxplot(color="black", 
                 fill="light grey")

ggarrange(pct_func, pct_nonfunc, pct_hand, pct_capov, pct_caple, pct_rural, pct_pop, pct_localpop, 
          ncol = 2, 
          nrow = 4)
```

Noticed that since we use ratios, the values are relatively congregated without outliers.

### 5.3 Choropleth map

We can draw choropleth map to visualize the distribution of each percentage variables in each polygon using code below.

```{r}
pct_func.map <- tm_shape(nga_wp) + 
  tm_fill(col = "pct_functional",
          n = 5,
          style = "jenks", 
          title = "Percentage of Functional Water Points") + 
  tm_borders(alpha = 0.5) +
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)

pct_nonfunc.map<-tm_shape(nga_wp)+
  tm_fill(col="pct_non-functional",
          n=5,
          stype="jenks",
          title = "Percentage of Non-Functional Water Points")+ 
  tm_borders(alpha = 0.5) +
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)

pct_hand.map<-tm_shape(nga_wp)+
  tm_fill(col="pct_hand-pump",
          n=5,
          style="jenks",
          title="Percentage of Non-Functional Water Points")+ 
  tm_borders(alpha = 0.5) +
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)

pct_capov.map<-tm_shape(nga_wp)+
  tm_fill(col="pct_cap>=1000",
          n=5,
          style="jenks",
          title="Percentage of Usage Capacity >=1000 Water Points")+ 
  tm_borders(alpha = 0.5) +
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)

pct_caple.map<-tm_shape(nga_wp)+
  tm_fill(col="pct_cap<1000",
          n=5,
          style="jenks",
          title="Percentage of Usage Capacity <1000 Water Points")+ 
  tm_borders(alpha = 0.5) +
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)

pct_rural.map<-tm_shape(nga_wp)+
  tm_fill(col="pct_rural",
          n=5,
          style="jenks",
          title="Percentage of Rural Water Points")+ 
  tm_borders(alpha = 0.5)+
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE) 

pct_pop.map<-tm_shape(nga_wp)+
  tm_fill(col="pct_pop",
          n=5,
          style="jenks",
          title="Percentage of Water Points with dense population")+ 
  tm_borders(alpha = 0.5)+
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE) 

pct_localpop.map<-tm_shape(nga_wp)+
  tm_fill(col="pct_localpop",
          n=5,
          style="jenks",
          title="Percentage of Water Points with dense local population")+ 
  tm_borders(alpha = 0.5)+
  tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE) 

tmap_arrange(pct_func.map, pct_nonfunc.map, pct_hand.map, pct_capov.map, pct_caple.map, pct_rural.map, pct_pop.map, pct_localpop.map,
          ncol = 2)
```

From the plots above, notice that areas in the north of the country have higher rate of functional water points, therefore, most water points in the south areas are non-functional. In addition, 50% of the country is equipped with hand-pumped water, which is low-level mechanical. The distributions of *Hand-pumped water points* and *water points with less than 1000 usage capacity* is aligned with each other. Lastly, almost water points are located in rural areas around the country. And the districts with dense population are quite dispersed, mostly located in the south parts of the country.

## 6 Correlation Analysis

### 6.1 Correlation Hierarchy Analysis

Before we start clustering, the first thing should be checking correlation between variables. We can use *corrplot.mixed()* function of ***corrplot*** package to visualise and analyse the correlation of the input variables.

```{r}
cluster_vars <- nga_wp %>%
  st_set_geometry(NULL)

cluster_vars.cor = cor(cluster_vars[,11:18])
cluster_vars.cor

corrplot.mixed(cluster_vars.cor,
         lower = "ellipse", 
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

From the proximity matrix above, noticed that percentage of **functional** water point and percentage of **non**-**functional** water point have highly correlation of -0.86 (\<-0.85); percentage of **hand**-**pumped** water point and **usage capacity \>=1000** water point have highly correlation of **-0.90 (\<-0.85)**; percentage of **hand-pumped** water point and **usage capacity \<1000** water point have highly correlation of **0.99 (\>0.85)**; percentage of **usage capacity \<1000** water point and **usage capacity \>=1000** water point have highly correlation of **-0.91 (\<-0.85)**.

Therefore, we remove *pct_functional, pct_hand-pump,* and *pct_cap\>=1000,* which mean percentage of functional water points, percentage of water points with hand-pump, and percentage of water points with capacity more than 1000 respectively.

### 6.2 Extracting clustering analysis

Before we proceed with clustering analysis, we should first extract clustering variables. As we mentioned above, we can delete any one variable which has high correlation with another variable. Now we can delete *pct_functional, pct_hand-pump,* and *pct_cap\>=1000.*

```{r}
wpt_clu<-select(cluster_vars,c(12,14,16,17,18))
head(wpt_clu,10)
```

#### 6.2.1 Data standarlisation

As shown in session 5.2 (EDA), the distribution of rural area water points is highly skewed, which may has impact on clustering analysis. For the reason that the data scale for rural area water points is already between 0-1, we use `scale`() to perform **Z-Score** standardisation to the clustering variables and review the standardised data using *`describe`*() of *psych* package.

```{r}
wpt_clu.s<-wpt_clu%>%
  mutate(pct_rural=exp(cluster_vars$pct_rural))
head(wpt_clu.s)
```

#### 6.2.2 Visualising standardised variable

Now let review the distribution of the standardised variable.

```{r}
ruralhist<-ggplot(data = wpt_clu.s,
       aes(x=`pct_rural`))+
  geom_histogram(bins=20,
                 color="black",
                 fill="orange")

pct_ruralhist <- ggplot(data=nga_wp, 
             aes(x= `pct_rural`)) +
  geom_histogram(bins=20, 
                 color="black", 
                 fill="light grey")

ruralbox<-ggplot(data = wpt_clu.s,
                 aes(x=`pct_rural`))+
  geom_boxplot(color="black",
          fill="orange")

pct_ruralbox <- ggplot(data=nga_wp, 
             aes(x= `pct_rural`)) +
  geom_boxplot(color="black", 
                 fill="light grey")

ggarrange(ruralhist,pct_ruralhist,ruralbox, pct_ruralbox,
         ncol=2,
         nrow = 2)
```

As shown in the plots above, the standardised variable is still highly skewed. Therefore, we still use the original variable.

### 7 Clustering Analysis

#### 7.1 Computing proximity matrix

We will compute the proximity matrix by using `dist`() of R. `dist()` supports six distance proximity calculations, they are: **euclidean, maximum, manhattan, canberra, binary and minkowski**. We use Euclidean as the method to compute the proximity matrix.

First, we compute the proximity matrix for the clustering matrix based on Euclidean method.

```{r}
proxmat <- dist(wpt_clu, method = 'euclidean')
```

#### 7.2 Computing hierarchical clustering

Then, we compute the hierarchical clustering based on *Ward.D* method.

```{r}
hclust_ward <- hclust(proxmat, method = 'ward.D')
```

We can then plot the tree by using *plot()* of R Graphics as shown in the code chunk below, where *cex* means size of the font.

```{r}
plot(hclust_ward, cex=0.6)
```

The `agnes()` function can get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure). Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).

The code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.

```{r}
m <- c( "average", "single", "complete", "ward")

names(m)<-c( "average", "single", "complete", "ward")

ac <- function(x) {
  agnes(cluster_vars, method = x)$ac
}

map_dbl(m, ac)
```

With reference to the output above, we can see that Ward's method provides the strongest clustering structure, which has agglomerative coefficient of 0.9918502, among the four methods assessed. Hence, in the subsequent analysis, only Ward's method will be used.

#### 7.3 Determining optimal cluster

Here are three commonly used methods to determine the optimal clusters, they are:

1.  Direct methods:

-   Elbow Method

-   Average Silhouette Method

2.  Statistical methods:

-   Gap Statistic Method

##### 7.3.1 Gap statistics method

The **gap statistic** compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.

To compute the gap statistic, `clusGap`*()* of **cluster** package will be used.

```{r}
set.seed(12345)
gap.stat <- clusGap(wpt_clu, 
                    FUN = hcut, 
                    nstart = 25, 
                    K.max = 20, 
                    B = 50)
# Print the result
print(gap.stat, method = "firstmax")
```

Also note that the `hcut()` function is available only in **factoextra** package. It computes hierarchical clustering and cut the tree in k pre-specified clusters.

Next, we can visualise the plot by using `fviz_gap_stat`*()* of **factoextra** package.

```{r}
fviz_gap_stat(gap.stat)
```

Then we can try kmeans method.

```{r}
set.seed(12345)
gap.kmean <- clusGap(wpt_clu, 
                    FUN = kmeans, 
                    nstart = 25, 
                    K.max = 20, 
                    B = 50)
# Print the result
print(gap.kmean, method = "firstmax")
```

```{r}
fviz_gap_stat(gap.kmean)
```

By examine the gap statistic graph, the 7-cluster gives the largest gap statistic for kmeans method. But since we have a highly skewed variable *pct_rural,* and our data set isn't very large, we choose hierarchical analysis in our subsequent analysis.

#### 7.4 Interpreting the dendrograms

We can draw a dendrogram with a border around the selected clusters by using *rect.hclust()* of R stats. The argument *border* is used to specify the border colors for the rectangles.

```{r}
plot(hclust_ward, cex = 0.6)
rect.hclust(hclust_ward, 
            k = 6, 
            border = 2:5)
```

From the dendrogram, we can see 6 clusters are shown based on *ward.D* method.

#### 7.5 Visually driven hierarchical clustering analysis

Now we can plot a heatmap to visualise the hierarchical clustering more clearly.

##### 7.5.1 Transforming the data frame into a matrix

The data will be analysed was loaded into a data frame, but it has to be a data matrix to make the heatmap. Code chunk below will be used to transform the data frame into a matrix.

```{r}
wpt_clu_mat <- data.matrix(wpt_clu)
```

##### 7.5.2 Plotting interactive cluster heatmap

In the code chunk below, the *heatmaply()* of heatmaply package is used to build an interactive cluster heatmap.

```{r}
heatmaply(normalize(wpt_clu_mat),
          Colv=NA,
          dist_method = "euclidean",
          hclust_method = "ward.D",
          seriate = "OLO",
          colors = Blues,
          k_row = 6,
          margins = c(NA,200,60,NA),
          fontsize_row = 4,
          fontsize_col = 5,
          main="Geographic Segmentation of Nigeria by Water Point Indicators",
          xlab = "Water Point Indicators",
          ylab = "Townships of Nigeria"
          )
```

From the heatmap, we can clearly see the quite distinct segmentation of clusters.

-   For cluster 1 (the top one), it shows that water points in these areas are relatively highly functional, with capacity less than 1000, in urban areas, with few population and few local (\<1 km) population.

-   For cluster 2, it shows that water points in these areas are also relatively highly functional, with capacity less than 1000, with few population and few local (\<1 km) population, but mostly in rural areas.

-   For cluster 3, it shows that water points in these areas are also with capacity mostly less than 1000, with few population and few local (\<1 km) population, mostly in rural areas, but relatively highly non-functional.

-   For cluster 4, it shows that water points in these areas are also with capacity mostly more than 1000, with few district population, relatively many local (\<1 km) population, mostly in urban areas, but relatively non-functional.

-   For cluster 5, it shows that water points in these areas are also with capacity mostly more than 1000, with dense district population and dense local (\<1 km) population, mostly in urban areas, and relatively functional.

-   For cluster 6, it shows that water points in little proportion of areas are also with capacity mostly more than 1000, with little district population and little local (\<1 km) population, mostly in urban areas, and mostly non-functional.

##### 7.5.3 Mapping the clusters formed

With closed examination of the dendragram above, we have decided to retain **6 clusters**. `cutree()` of R Base will be used in the code chunk below to derive a 6-cluster model.

```{r}
groups <- as.factor(cutree(hclust_ward, k=6))
```

In order to visualise the clusters, the *groups* object needs to be appended onto *nga_wp* simple feature object. And we need 3 steps to achieve this.

-   the *groups* list object will be converted into a matrix;

-   `cbind()` is used to append *groups* matrix onto *nga_wp* to produce an output simple feature object called `nga_sf_cluster`; and

-   `rename()` of **dplyr** package is used to rename *as.matrix.groups* field as *CLUSTER*.

Before continuing, we create a tidier data frame named *nga_5,* which only contains 5 variables, from *nga_wp .*

```{r}
nga_5<-nga_wp%>%
  select(c(13,15,17,18,19),)

nga_sf_cluster <- cbind(nga_5, as.matrix(groups)) %>%
  rename(`CLUSTER`=`as.matrix.groups.`)
```

Next, `qtm()` of ***tmap*** package is used to plot the choropleth map showing the cluster formed.

```{r}
qtm(nga_sf_cluster, "CLUSTER")
```

### 8 Spatially Constrained Clustering - SKATER approach

Now we use spatially constrained clustering with SKATER method to take spatial attributes into consideration.

#### 8.1 Converting into SpatialPolygonDataFrame

First, we need to convert nga_wpt into SpatialPolygonsDataFrame called *nga_sp* using code chunk below. This is because SKATER function only support **sp** objects such as SpatialPolygonDataFrame.

```{r}
nga_sp <- as_Spatial(nga_5)
```

#### 8.2 Computing neighbor list

Next, poly2nd() of **spdep** package will be used to compute the neighbours list from polygon list.

```{r}
nga.nb <- poly2nb(nga_sp)
summary(nga.nb)
```

These are used as the nodes for the graph representation. From the report above, we see that one region numbered **86** has no link. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.

Take a look at the file *nga_wp*, this region number 86 is named ***Bakassi***, with other attributes all 0, meaning no water points in this region.![](images/tempsnip-02.png)

```{r}
plot(nga_sp, 
     border=grey(.5))
plot(nga.nb, 
     coordinates(nga_sp), 
     col="blue", 
     add=TRUE)
plot(nga_sp[86,],
     border="red",
     add=TRUE)
```

We can see from the map above that a little region in red border, which represents region number 86 named ***Bakassi,*** is at the south of the country having no neighbors.

#### 8.3 Computing minimum spanning tree

##### 8.3.1 Calculating edge costs

Next, `nbcosts()` of **spdep** package is used to compute the cost of each edge. It is the distance between its nodes. This function compute this distance using a data.frame with observations vector in each node. But this function requires no disconnected nodes. Therefore we first extract the region **86** having no neighbors from the original sf data frame *nga_5.*

```{r}
nga_0<-nga_5[-86,]
rownames(nga_0)<-NULL
```

Then we convert the sf frame into SpatialPolygonsDataFrame as clarified above.

```{r}
nga_sp <- as_Spatial(nga_0)
```

The code chunk below is used to compute the cost of each edge.

```{r}
nga.nb <- poly2nb(nga_sp)
summary(nga.nb)

lcosts <- nbcosts(nga.nb,wpt_clu)
```

Next, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed ***lcosts*** as the weights. Note that we specify the *style* as **B** to make sure the cost values are not row-standardised.

```{r}
nga.w <- nb2listw(neighbours=nga.nb, 
                   glist=lcosts, 
                   style="B",
                  zero.policy = TRUE)

summary(nga.w)
```

##### 8.3.2 Computing minimum spanning tree

The minimum spanning tree is computed by mean of the `mstree()` of ***spdep*** package as shown in the code chunk below.

```{r}
nga.mst <- mstree(nga.w, ini = NULL)
```

After computing the MST, we can check its class and dimension by using the code chunk below.

```{r}
class(nga.mst)
```

```{r}
dim(nga.mst)
```

Note that the dimension is 772 and not 773. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes. We can check the data frame by using `head().`

```{r}
head(nga.mst)
```

The plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge.

```{r}
plot(nga_sp, border=gray(.5))
plot.mst(nga.mst, 
         coordinates(nga_sp), 
         col="blue", 
         cex.lab=0.3, 
         cex.circles=0.005, 
         add=TRUE)
```

#### 8.4 Computing spatially constrained clusters using SKATER method

The code chunk below compute the spatially constrained cluster using `skater()` of ***spdep*** package. The mandatory arguments *ncuts* is actually value of one less than the clusters, so we set it as 5 referring to the optimal 6 clusters.

```{r}
clust6 <- skater(edges = nga.mst[,1:2], 
                 data = wpt_clu, 
                 method = "euclidean", 
                 ncuts = 5)
```

We can examine the contents by using the code chunk below.

```{r}
str(clust6)
```

We can check the cluster assignment by using the code chunk below.

```{r}
ccs6 <- clust6$groups
ccs6
```

Noticed that all nodes are assigned into one cluster. We can find out how many observations are in each cluster by means of the table command.

```{r}
freq(ccs6)
```

Seen that around half water points belong to cluster 2, followed by cluster 1, 6, 3, 4 and 5. Lastly, we can also plot the pruned tree that shows the 5 clusters on top of the township area.

```{r}
plot(nga_sp, border=gray(.5))
plot(clust6, 
     coordinates(nga_sp), 
     cex.lab=.3,
     groups.colors=c("red","green","blue", "brown", "pink"),
     cex.circles=0.005, 
     add=TRUE)
```

#### 8.5 Visualising the clusters in choropleth map

The code chunk below is used to plot the newly derived clusters by using SKATER method.

```{r}
groups_mat <- as.matrix(clust6$groups)
nga_sf_spatialcluster <- cbind(nga_0, as.factor(groups_mat)) %>%
  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)
qtm(nga_sf_spatialcluster, "SP_CLUSTER")
```

For easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.

```{r}
hclust.map <- qtm(nga_sf_cluster,
                  "CLUSTER") + 
  tm_borders(alpha = 0.5)+
  tm_layout(main.title = "Hierarchical Clustering",
            legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)

sclust.map <- qtm(nga_sf_spatialcluster,
                   "SP_CLUSTER") + 
  tm_borders(alpha = 0.5)+
  tm_layout(main.title = "Spatially Clustering Using SKATER",
            legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE)
tmap_arrange(hclust.map, sclust.map,
             asp=NA, ncol=2)
```

Noticed that spatially constrained clustering using SKATER puts heavily weights on spatial correlation. Regions in adjacent are mostly likely divided into one cluster.

### 9 Spatially Constrained Clustering: ClustGeo Method

Next we will be using functions provided by **ClustGeo** package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis.

#### 9.1 Ward-like hierarchical clustering: ClustGeo

ClustGeo package provides function called `hclustgeo()` to perform a typical Ward-like hierarchical clustering like `hclust()`.

To perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.

```{r}
nongeo_cluster <- hclustgeo(proxmat)
plot(nongeo_cluster, cex = 0.5)
rect.hclust(nongeo_cluster, 
            k = 6, 
            border = 2:5)
```

#### 9.2 Mapping the clusters formed

Similarly, we can plot the clusters on a categorical area shaded map.

```{r}
groups <- as.factor(cutree(nongeo_cluster, k=6))

nga_sf_ngeo_cluster <- cbind(nga_5, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)

qtm(nga_sf_ngeo_cluster, "CLUSTER")+
  tm_layout(main.title = "Non-spatially Constrained Hierarchichal Clustering")
```

#### 9.3 Spatially Constrained Hierarchical Clustering

Before we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using `st_distance()` of sf package.

```{r}
dist <- st_distance(nga_5, nga_5)
distmat <- as.dist(dist)
```

Next, `choicealpha()` will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.

```{r}
cr <- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)
```

With reference to the graphs above, alpha = 0.4 will be used as shown in the code chunk below.

```{r}
clustG <- hclustgeo(proxmat, distmat, alpha = 0.4)
```

Next, `cutree()` is used to derive the cluster object.

```{r}
groups <- as.factor(cutree(clustG, k=6))
groups
```

We will then join back the group list with *nga_5* polygon feature data frame by using the code chunk below.

```{r}
nga_sf_Gcluster <- cbind(nga_5, as.matrix(groups)) %>%
  rename(`CLUSTER` = `as.matrix.groups.`)
```

We can now plot the map of the newly delineated spatially constrained hierarchical clusters with the non-spatially constrained hierarchical clusters as shown below.

```{r}
schc<-qtm(nga_sf_Gcluster, "CLUSTER")+
   tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE, 
            main.title="Choropleth Map of Nigeria Based on Spatially Constrained Hierarchical Clustering-ClustGeo")
nshc<-qtm(nga_sf_ngeo_cluster, "CLUSTER")+
   tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE, 
            main.title ="Choropleth Map of Nigeria Based on Non-spatially Constrained Hierarchical Clustering-ClustGeo")
hc<-qtm(nga_sf_cluster, "CLUSTER" )+
   tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE,
            main.title ="Choropleth Map of Nigeria Based on Non-spatially Constrained Hierarchical Clustering")

sk<-qtm(nga_sf_spatialcluster, "SP_CLUSTER")+
   tm_layout(legend.outside = TRUE,
            legend.height = 0.45, 
            legend.width = 5.0,
            legend.position = c("right", "bottom"),
            frame = FALSE,
            main.title ="Choropleth Map of Nigeria Based on Non-spatially Constrained Hierarchical Clustering-SKATER")
tmap_arrange(schc,nshc,hc,sk,
             ncol=2)
```

From 4 choropleth maps above, it's clear that spatially constrained clustering of SKATER method relies heavieliest on neighboring weights, therefore the delineated districts are quite tidy and congregated. While spatially constrained clustering of ClustGeo method also relies on spatial correlation but not as heavily as SKATER. Clusterings of hierarchical based on hclust() and hclustgeo() are quite the same, both have many crossover parts espectially within cluster 1, 3, 4, 5, which have less proportions than cluster 2 and 6 across the country.
